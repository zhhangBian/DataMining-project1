# 第一章 背景

长期以来，国民健康水平提升都是我国社会发展的重要议题，随着我国经济发展和民众健康意识的不断提升，健康保险作为政府医疗保障体系的重要补充力量，正发挥越来越积极的作用[1]。健康保险不仅能够为个人减轻因健康问题带来的经济负担，同时也在一定程度上促进了整个社会的健康管理水平的提升。

然而，随着健康险市场的不断扩大和消费者需求的日益多样化，保险公司面临着如何准确评估保险风险以及产品合理定价品的挑战。传统的风险评估方法往往基于专家经验规则和历史数据。但这种方法往往需要大量的人工工作量，且具有较强的主观性，并在面对复杂多变的健康风险时，难以准确预测和评估风险，从而影响到保险产品的质量和服务的效率。

数据挖掘技术的发展，特别是机器学习和深度学习技术的发展，为健康险风险评估提供了新的解决方案。通过分析大量的健康数据、消费者行为数据以及环境因素等，数据挖掘技术能够帮助保险公司发现数据中的模式和规律，从而更准确地预测健康风险，优化保险产品设计和服务。

本项目将基于消费者的健康数据、行为数据等信息，预估发生健康险保险事故（即出险）的概率。具体包括以下内容：

1. 对消费者的信息和保险信息进行数据预处理和统计分析，探索数据特征与出险结果之间的关系，并基于数据分析结果进行特征工程（如特征的选择等）。
2. 设计适用于健康险评估的数据挖掘算法，以评估出险概率的等级，分为0到3共4级，数字越大则出险概率越高。
3. 采用不少于2种指标[3]，对模型的性能进行全面的评估。

# 第二章 任务分析

我们使用的数据集包含了客户的各种信息以及对应的响应情况。数据集中的特征包括就业信息、保险历史、医疗记录等，而响应情况则是客户是否做出了某种响应的二元分类结果。

本实验旨在使用机器学习技术构建一个模型，对给定数据集进行分类任务。具体而言，我们的目标是训练一个模型，根据一系列特征预测出客户的响应（Response）情况。

任务重点内容在于如何对数据进行预处理，并且在众多数据中筛选出对于二元分类结果影响较大的数据，从而选择合适的数据以提高预测准确率。

# 第三章 算法设计

首先我们对于数据进行了分析和预处理，通过统计并可视化的呈现出各个指标对于最终分类结果的贡献，即统计出不同指标在不同类别中的分布情况，如果在各个类别中的分布情况都基本一致，那么我们认为这个指标对于分类并没有产生贡献，所以将该指标剔除，不作为最终加入模型进行训练的指标，以此筛选出对于分类贡献较大的指标，从而提高预测准确率。

我们最终选用了AdaBoost集成学习方法，通过组合多个弱学习器来构建一个强大的分类器，通过迭代训练一系列弱分类器（决策树等），每个弱分类器仅能对数据进行简单的分类，甚至只比随机猜测略好。在每一轮迭代中，AdaBoost都会调整训练数据的权重，使得前一轮分类错误的样本在下一轮训练中得到更多的关注。 最终的强分类器是将所有弱分类器的结果加权组合而成，其中每个弱分类器的权重由其在分类过程中的表现决定。

相较于随机森林，AdaBoost在处理分类问题时具有很高的精度和泛化能力，而且由于我们的数据是来源于现实生活中的问题，该算法在面对现实生活中的不平衡数据集有较好的处理能力，最终实验结果也证明该算法确实有效的提升了准确率。

# 第四章 实验

整体配置基本与原baseline方法保持一致，在实验当中，我们选取并修改了加入其中作为考量的指标，根据指标在不同分类中呈现出的分布情况进行选取，根据经验和实验结果辅助判断，筛选出对于分类情况影响较大的指标，对于连续型数值变量我们考虑其均值、方差等，对于离散型分类变量我们观察其在各个类别中的分类比例，最终选取的结果为：

```python
['Product_Info_2', 'Product_Info_6', 'Employment_Info_3', 'Employment_Info_5', 'InsuredInfo_1', 'InsuredInfo_3', 'InsuredInfo_6', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3','Insurance_History_4','Insurance_History_7','Insurance_History_8','Insurance_History_9','Family_Hist_1','Medical_History_4','Medical_History_6', 'Medical_History_9', 'Medical_History_13', 'Medical_History_16', 'Medical_History_18', 'Medical_History_22', 'Medical_History_23', 'Medical_History_30', 'Medical_History_33', 'Medical_History_39','Medical_History_41','Medical_Keyword_3','Medical_Keyword_15','Medical_Keyword_23','Medical_Keyword_25', 'Medical_Keyword_48', 'Product_Info_3', 'Product_Info_4', 'Ins_Age', 'Wt', 'BMI', 'Employment_Info_1', 'Employment_Info_2', 'Employment_Info_4', 'Employment_Info_6', 'Medical_History_1']
```

在之后我们选用了策略为`quantile`离散化稠密特征。分类算法方面我们比较了`BaggingClassifier`、`RandomForestClassifier`、`AdaBoostClassifier`、`CatBoost`、`Kmeans`等分类算法，最终选取`BaggingClassifier`，分类器选择为`DecisionTreeClassifier`。

正如算法设计中所说，在模型方面我们在baseline的随机森林修改为AdaBoost，最终获得的实验准确率也有所提高，对于参数，决策树直接选择10层决策树，本来以为会过拟合，结果出乎意料效果还可以

在评价指标方面，我们考虑并分析了macro average与micro average两种评价指标，其中宏观平均（Macro-average）将每个类别的指标（如精确度、召回率和F1分数）分别计算出来，然后取它们的算术平均值。给每个类别的指标被赋予相同的权重，不管类别的大小或频率。当类别数量较少，且每个类别都很重要时，宏观平均是一个不错的选择；微观平均（Micro-average）是先计算所有类别的总体真正例、假正例和假负例，然后基于这些总数计算指标，通过汇总所有类别的预测和真实标签来计算，因此对类别的不平衡性更加敏感。当类别数量较多，且类别之间存在不平衡性时，微观平均通常更合适。在差距方面，由于本任务的多分类目标之间是有序的，我们改为使用平方距离来反映差距，尝试利用有序性，更好的衡量所谓“错的更少”的指标

最终实验结果：Test accuracy = 0.6507, f1_score = 0.6507,  mae  = 1.4393

|      | precision | recall | f1-score | support |
| ---- | --------- | ------ | -------- | ------- |
| 0    | 0.67      | 0.88   | 0.76     | 1856    |
| 1    | 0.59      | 0.5    | 0.59     | 1240    |
| 2    | 0.25      | 0.03   | 0.05     | 165     |
| 3    | 0.57      | 0.31   | 0.40     | 896     |

# 第五章 分工情况

bzh：选取连续性特征，改进离散化稠密特征方式，选用AdaBoost模型

qy：选取离散化特征，负责实验报告撰写和答辩ppt制作

fxk：实现特征可视化，将特征值更加直观显示，便于选取

集体讨论参与训练特征的选取

# 第六章 结论与收获

通过本次实验，我们发现相较于随机森林，AdaBoost算法在面对现实生活中的不平衡数据时展现出了更好的精度和泛化能力；了解了macro average与micro average两种评价指标在面对不同问题时应该如何选取和使用，详细了解了各自的特点。

经过本次实验代码的实现和改进，我们更加深刻的体会和了解到了数据预处理的重要性，以及在评价时如何选取合适的特征和评价指标，对于随机森林和AdaBoost算法的应用特点有了更为直观地感受，对于数据的相关指标和处理方法有了进一步的了解和认识，收获颇丰
